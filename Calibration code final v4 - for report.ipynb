{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r\"C:\\Users\\laura\\OneDrive - Danmarks Tekniske Universitet\\Dokumenter\\AS DTU\\FALL 2024 DTU\\Perception for Autonomous Systems\\Final project\\34759_final_project_raw\\34759_final_project_raw\\calib\"\n",
    "path_cam2 = os.path.join(base_path, \"image_02\", \"data\")\n",
    "path_cam3 = os.path.join(base_path, \"image_03\", \"data\")\n",
    "\n",
    "# Get all image paths\n",
    "cam2 = sorted(glob.glob(os.path.join(path_cam2, \"*.png\")))\n",
    "cam3 = sorted(glob.glob(os.path.join(path_cam3, \"*.png\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 2 Calibration Results:\n",
      " K2  =\n",
      " [[962.64   0.   713.77]\n",
      " [  0.   969.63 222.44]\n",
      " [  0.     0.     1.  ]], \n",
      " D2 =\n",
      " [[-0.36  0.19 -0.   -0.   -0.05]]\n",
      "Camera 3 Calibration Results: \n",
      " K3 =\n",
      " [[911.92   0.   696.46]\n",
      " [  0.   922.49 236.67]\n",
      " [  0.     0.     1.  ]], \n",
      " D3 =\n",
      " [[-0.35  0.19  0.   -0.   -0.07]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Arrays to store real-world points and image points\n",
    "objpoints = []  # 3D points in real-world space\n",
    "imgpoints1 = []  # 2D points in the image from camera 1\n",
    "imgpoints2 = []  # 2D points in the image from camera 2\n",
    "\n",
    "# Store detected corners to avoid duplicates\n",
    "detected_corners1 = []\n",
    "detected_corners2 = []\n",
    "\n",
    "# Images to show all detections\n",
    "all_corners_img1 = None\n",
    "all_corners_img2 = None\n",
    "\n",
    "\n",
    "# Boxes x, y, w, h\n",
    "roi2 = [[130, 120, 180, 210], [370, 170, 110, 140], [460, 70, 170, 75], [510, 270, 90, 120], [490, 385, 180, 130], [680, 290, 90, 120], [790, 130, 130, 100], [800, 300, 100, 120], [1000, 60, 200, 100], [1100, 250, 100, 130], [1000, 380, 144, 70], [1240, 160, 75, 280], [1320, 180, 70, 170]]\n",
    "roi3 = [[40, 120, 240, 230], [300, 170, 130, 150], [372, 83, 164, 77], [450, 260, 90, 120], [380, 335, 280, 190], [600, 290, 90, 120], [680, 80, 230, 160], [690, 250, 200, 180], [890, 10, 300, 160], [990, 240, 100, 120], [895, 365, 138, 72], [1136, 157, 58, 262], [1200, 160, 66, 180]]\n",
    "\n",
    "gridsizes = [(7,11), (7,11), (5,7), (5,7), (5,7), (5,7), (5,7), (5,7), (5,7), (5,7), (5,7), (5,15), (5,7)]\n",
    "\n",
    "\n",
    "for i, (fname1, fname2) in enumerate(zip(cam2[:1], cam3[:1])):\n",
    "    \n",
    "    # Read images\n",
    "    img1_original = cv2.imread(fname1)\n",
    "    img2_original = cv2.imread(fname2)\n",
    "    h, w = img1_original.shape[:2]\n",
    "    \n",
    "    # Resize images to improve detection\n",
    "    img1_resized = cv2.resize(img1_original, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    img2_resized = cv2.resize(img2_original, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray1 = cv2.cvtColor(img1_resized, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(img2_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Enhance contrast and brightness\n",
    "    alpha = 1.8  # Contrast control\n",
    "    beta = 10    # Brightness control\n",
    "    gray1 = cv2.convertScaleAbs(gray1, alpha=alpha, beta=beta)\n",
    "    gray2 = cv2.convertScaleAbs(gray2, alpha=alpha, beta=beta)\n",
    "\n",
    "    # Create base images for combined detection visualization\n",
    "    if all_corners_img1 is None:\n",
    "        all_corners_img1 = img1_original.copy()\n",
    "        all_corners_img2 = img2_original.copy()\n",
    "\n",
    "    for j, (box1, box2, size) in enumerate(zip(roi2, roi3, gridsizes)):\n",
    "        \n",
    "        # Prepare real-world 3D points\n",
    "        objp = np.zeros((size[0] * size[1], 3), np.float32)\n",
    "        objp[:, :2] = np.mgrid[0:size[0], 0:size[1]].T.reshape(-1, 2)\n",
    "        objp *= 10e-2  # Square size in meters (10 cm)\n",
    "\n",
    "        # Create masks for ROIs\n",
    "        mask1 = np.zeros_like(gray1)\n",
    "        mask2 = np.zeros_like(gray2)\n",
    "        mask1[box1[1]*2:box1[1]*2+box1[3]*2, box1[0]*2:box1[0]*2+box1[2]*2] = 255\n",
    "        mask2[box2[1]*2:box2[1]*2+box2[3]*2, box2[0]*2:box2[0]*2+box2[2]*2] = 255\n",
    "\n",
    "        gray1_masked = cv2.bitwise_and(gray1, mask1)\n",
    "        gray2_masked = cv2.bitwise_and(gray2, mask2)\n",
    "\n",
    "        # Detect chessboards\n",
    "        ret1, corners1 = cv2.findChessboardCorners(gray1_masked, size)\n",
    "        ret2, corners2 = cv2.findChessboardCorners(gray2_masked, size)\n",
    "\n",
    "\n",
    "\n",
    "        if ret1 and ret2:\n",
    "            # Refine corners\n",
    "            corners1 = cv2.cornerSubPix(\n",
    "                gray1_masked, corners1, (7, 7), (-1, -1),\n",
    "                (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "            )\n",
    "            # corners1 = corners1[::-1]\n",
    "            corners2 = cv2.cornerSubPix(\n",
    "                gray2_masked, corners2, (7, 7), (-1, -1),\n",
    "                (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "            )\n",
    "            # corners2 = corners2[::-1]\n",
    "\n",
    "            # Scale corners back to original size\n",
    "            corners1 /= 2\n",
    "            corners2 /= 2\n",
    "\n",
    "            # def enforce_consistent_order(corners1, corners2):\n",
    "            #     # Check the orientation of the first row\n",
    "            #     if np.linalg.norm(corners1[0] - corners1[-1]) < np.linalg.norm(corners2[0] - corners2[-1]):\n",
    "            #         corners2 = corners2[::-1]  # Reverse corners2 if needed\n",
    "\n",
    "            #     # Check the orientation of the first column\n",
    "            #     if np.linalg.norm(corners1[0] - corners1[size[0] - 1]) < np.linalg.norm(corners2[0] - corners2[size[0] - 1]):\n",
    "            #         corners2 = corners2.reshape(size[::-1])[::-1].reshape(-1, 1, 2)  # Flip vertically if needed\n",
    "\n",
    "            #     return corners1, corners2\n",
    "            \n",
    "            # corners1, corners2 = enforce_consistent_order(corners1, corners2)\n",
    "            def reverse_columns(corners, grid_size):\n",
    "                # Reshape to rows x columns\n",
    "                corners_grid = corners.reshape(grid_size[1], grid_size[0], 2)  # (cols, rows, 2)\n",
    "                # Reverse columns\n",
    "                corners_grid = corners_grid[:, ::-1, :]\n",
    "                # Flatten back to the original shape\n",
    "                return corners_grid.reshape(-1, 1, 2)\n",
    "\n",
    "            if j in [4,10]:\n",
    "                # print(\"Reversing columns\")\n",
    "                corners2 = corners2[::-1]\n",
    "                # corners2 = reverse_columns(corners2, size)\n",
    "\n",
    "            cv2.drawChessboardCorners(all_corners_img1, size, corners1, ret1)\n",
    "            cv2.drawChessboardCorners(all_corners_img2, size, corners2, ret2)\n",
    "            # plt.figure(figsize=(15, 7))\n",
    "            # plt.subplot(2, 2, 1)\n",
    "            # plt.title(\"All Chessboards Camera Left\")\n",
    "            # plt.imshow(cv2.cvtColor(all_corners_img1, cv2.COLOR_BGR2RGB))\n",
    "            # plt.axis(\"off\")\n",
    "\n",
    "            # plt.subplot(2, 2, 2)\n",
    "            # plt.title(\"All Chessboards Camera Right\")\n",
    "            # plt.imshow(cv2.cvtColor(all_corners_img2, cv2.COLOR_BGR2RGB))\n",
    "            # plt.axis(\"off\")\n",
    "\n",
    "            # plt.subplot(2, 2, 3)\n",
    "            # plt.title(\"Mask Left\")\n",
    "            # plt.imshow(gray1_masked)\n",
    "            # plt.axis(\"off\")\n",
    "\n",
    "            # plt.subplot(2, 2, 4)\n",
    "            # plt.title(\"Mask Right\")\n",
    "            # plt.imshow(gray2_masked)\n",
    "            # plt.axis(\"off\")\n",
    "            # plt.show()\n",
    "\n",
    "            imgpoints1.append(corners1)\n",
    "            imgpoints2.append(corners2)\n",
    "            objpoints.append(objp)\n",
    "\n",
    "#Plot results\n",
    "\n",
    "\n",
    "for img_path2, img_path3 in zip(cam2, cam3):\n",
    "    img2 = cv2.imread(img_path2)  # Camera 2 image\n",
    "    img3 = cv2.imread(img_path3)  # Camera 3 image\n",
    "\n",
    "    # Get the image size (used for stereo calibration)\n",
    "    img_size_2 = (img2.shape[1], img2.shape[0])  # (width, height)\n",
    "    img_size_3 = (img3.shape[1], img3.shape[0])  # (width, height)\n",
    "\n",
    "# Perform the calibration\n",
    "ret2, K2, D2, rvecs2, tvecs2 = cv2.calibrateCamera(objpoints, imgpoints1, img_size_2, None, None, criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, 1e-6))\n",
    "if not ret2:\n",
    "     raise RuntimeError(\"Camera 2 calibration failed.\")\n",
    "\n",
    "ret3, K3, D3, rvecs3, tvecs3 = cv2.calibrateCamera(objpoints, imgpoints2, img_size_3, None, None, criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, 1e-6))\n",
    "if not ret3:\n",
    "    raise RuntimeError(\"Camera 3 calibration failed.\")\n",
    "\n",
    "# Print results\n",
    "np.set_printoptions(suppress=True, precision=2) \n",
    "\n",
    "print(f\"Camera 2 Calibration Results:\\n K2  =\\n {K2}, \\n D2 =\\n {D2}\")\n",
    "print(f\"Camera 3 Calibration Results: \\n K3 =\\n {K3}, \\n D3 =\\n {D3}\")\n",
    "# print(f\"Camera 2 tvecs: \\n\", tvecs2 [0])\n",
    "# print(f\"Camera 3 tvecs: \\n\", tvecs3 [0])\n",
    "# print(f\"Camera 2 rvecs: \\n\", rvecs2 [0])\n",
    "# print(f\"Camera 3 rvecs: \\n\", rvecs3 [0])\n",
    "# print(f\"Camera 2 error: {ret2:.3f}\")\n",
    "# print(f\"Camera 3 error: {ret3:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stereo calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stereo Calibration Results: \n",
      "\n",
      "Rotation Matrix: \n",
      "[[ 1.    0.02 -0.02]\n",
      " [-0.02  1.   -0.01]\n",
      " [ 0.02  0.01  1.  ]]\n",
      "Translation Vector: \n",
      "[[-0.48]\n",
      " [-0.01]\n",
      " [ 0.09]]\n"
     ]
    }
   ],
   "source": [
    "flags = cv2.CALIB_FIX_INTRINSIC\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, 1e-6)\n",
    "\n",
    "# Stereo calibration\n",
    "ret, K2, D2, K3, D3, R, T, E, F = cv2.stereoCalibrate(\n",
    "    objpoints, imgpoints1, imgpoints2, K2, D2, K3, D3, img_size_2, criteria=criteria, flags=flags)\n",
    "\n",
    "print(f\"Stereo Calibration Results: \\n\")\n",
    "print(f\"Rotation Matrix: \\n{R}\")\n",
    "print(f\"Translation Vector: \\n{T}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stereo Rectification:\n",
      " R2 =\n",
      "[[ 0.98  0.04 -0.2 ]\n",
      " [-0.04  1.   -0.  ]\n",
      " [ 0.2   0.01  0.98]],\n",
      " P2 =\n",
      "[[1053.8     0.   1083.87    0.  ]\n",
      " [   0.   1053.8   206.78    0.  ]\n",
      " [   0.      0.      1.      0.  ]]\n",
      "R3 =\n",
      "[[ 0.98  0.02 -0.18]\n",
      " [-0.02  1.    0.01]\n",
      " [ 0.18 -0.01  0.98]],\n",
      " P3 =\n",
      "[[1053.8     0.   1083.87 -511.42]\n",
      " [   0.   1053.8   206.78    0.  ]\n",
      " [   0.      0.      1.      0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# Stereo rectification\n",
    "R2, R3, P2, P3, Q, roi1, roi2 = cv2.stereoRectify(\n",
    "    K2,\n",
    "    D2,\n",
    "    K3,\n",
    "    D3,\n",
    "    img_size_2,\n",
    "    R,\n",
    "    T,\n",
    "    alpha=0\n",
    ")\n",
    "\n",
    "# Print results\n",
    "np.set_printoptions(suppress=True, precision=2) \n",
    "\n",
    "print(f\"Stereo Rectification:\\n R2 =\\n{R2},\\n P2 =\\n{P2}\")\n",
    "print(f\"R3 =\\n{R3},\\n P3 =\\n{P3}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image size (you can use the size of the first image)\n",
    "img_size_2 = cv2.imread(cam2[0]).shape[:2][::-1]\n",
    "\n",
    "# Create the rectification maps\n",
    "map1x, map1y = cv2.initUndistortRectifyMap(K2, D2, R2, P2, img_size_2, cv2.CV_32F)\n",
    "map2x, map2y = cv2.initUndistortRectifyMap(K3, D3, R3, P3, img_size_2, cv2.CV_32F)\n",
    "\n",
    "# Process all the images\n",
    "for left_img_path, right_img_path in zip(cam2, cam3):\n",
    "    # Read the images\n",
    "    img1 = cv2.imread(left_img_path)  # Left camera image\n",
    "    img2 = cv2.imread(right_img_path)  # Right camera image\n",
    "\n",
    "    # Rectify the images\n",
    "    rectified_img1 = cv2.remap(img1, map1x, map1y, cv2.INTER_LINEAR)\n",
    "    rectified_img2 = cv2.remap(img2, map2x, map2y, cv2.INTER_LINEAR)\n",
    "\n",
    "    # # Show the rectified images using matplotlib\n",
    "    # fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    # axes[0].imshow(cv2.cvtColor(rectified_img1, cv2.COLOR_BGR2RGB))\n",
    "    # axes[0].set_title(f\"Rectified Left {os.path.basename(left_img_path)}\")\n",
    "    # axes[0].axis('off')  # Disable the axes\n",
    "\n",
    "    # axes[1].imshow(cv2.cvtColor(rectified_img2, cv2.COLOR_BGR2RGB))\n",
    "    # axes[1].set_title(f\"Rectified Right {os.path.basename(right_img_path)}\")\n",
    "    # axes[1].axis('off')  # Disable the axes\n",
    "\n",
    "    # plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
