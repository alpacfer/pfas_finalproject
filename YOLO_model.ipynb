{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "from IPython import display\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model_checkpoint/weights/best.pt'\n",
    "model = YOLO(model_path) #This is to load previously trained weights\n",
    " # model = YOLO('yolov11n.pt') #Use this to load the default YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "classes = ['Car', 'Cyclist', 'Pedestrian']  # Replace with your actual class names\n",
    "train_path = r'YOLO\\images\\train'  # Updated training dataset path\n",
    "valid_path = r'YOLO\\images\\val'  # Replace with your actual validation dataset path\n",
    "\n",
    "yaml_file = 'names:\\n'\n",
    "yaml_file += '\\n'.join(f'- {c}' for c in classes)\n",
    "yaml_file += f'\\nnc: {len(classes)}'\n",
    "yaml_file += f'\\ntrain: {str(train_path)}\\nval: {str(valid_path)}'\n",
    "with open('kitti.yaml', 'w') as f:\n",
    "    f.write(yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "train_results = model.train(\n",
    "    data='kitti.yaml', # Path to the dataset configuration file,\n",
    "    epochs=300, # Increased epochs\n",
    "    patience=0, # No early stopping\n",
    "    batch=16,# Batch size\n",
    "    imgsz=640,  # Image size\n",
    "    mixup=0.1,# Mixup augmentation factor\n",
    "    project='Perception-yolov11n-kitti', # Project name\n",
    "    name='Training',# Naming the experiment\n",
    "    resume = False,# Resume training from the last checkpoint\n",
    "    device=0)# Use GPU if available, specified as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [1,2,3]\n",
    "yolo_classes = ['Car', 'Pedestrian', 'Cyclist']\n",
    "image_width = 1242\n",
    "image_height = 370\n",
    "\n",
    "base_dir = r\"D:\\Chinmay\\MSc - DTU\\Course Material\\3rd Sem\\Perception\\Project\\34759_final_project_rect\"\n",
    "for seq_number in sequences:\n",
    "    model = YOLO(model_path)\n",
    "    seq_dir = os.path.join(base_dir, f\"seq_{seq_number:02d}\", \"image_02\", \"data\")\n",
    "\n",
    "    image_list = sorted([os.path.join(seq_dir, f) for f in os.listdir(seq_dir) if f.endswith(('.png', '.jpg'))])\n",
    "\n",
    "    output_file = f\"tracking_results_seq_{seq_number:02d}.txt\"\n",
    "    track_history = defaultdict(lambda: [])\n",
    "\n",
    "    # for image in image_list:\n",
    "    #     results = model.track(image, persist=True)\n",
    "    #     boxes = results[0].boxes.xywh.cpu()\n",
    "    #     track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for image_path in image_list:\n",
    "            # Get the filename from the path\n",
    "            image_name = os.path.basename(image_path)\n",
    "            \n",
    "            # Perform tracking on the image\n",
    "            results = model.track(image_path, persist=True,tracker=\"bytetrack.yaml\")\n",
    "            \n",
    "            # Process and save the results\n",
    "            for result in results:\n",
    "                boxes = result.boxes.xywh.cpu().numpy()  # Bounding boxes in [x, y, w, h] format\n",
    "                class_ids = result.boxes.cls.cpu().numpy()  # Class IDs\n",
    "                scores = result.boxes.conf.cpu().numpy()  # Confidence scores\n",
    "                track_ids = result.boxes.id.cpu().numpy() if result.boxes.id is not None else [-1] * len(boxes) # Track IDs\n",
    "                \n",
    "                # Write results for each object\n",
    "                for box, cls_id, track_id, score in zip(boxes, class_ids, track_ids,scores):\n",
    "                    cls_id = int(float(cls_id))\n",
    "                    track_id = int(track_id)\n",
    "                    x, y, w, h = box[0], box[1], box[2], box[3]\n",
    "                    x, y, w, h = map(float, [x, y, w, h])\n",
    "                    x1, y1 = int(x - w / 2), int(y - h / 2)\n",
    "                    x2, y2 = int(x + w / 2), int(y + h / 2)\n",
    "\n",
    "                    # PLACEHOLDERS\n",
    "                    truncated = 0  # Placeholder\n",
    "                    occluded = 0   # Placeholder\n",
    "                    alpha = -10.0  # Placeholder\n",
    "                    bbox = f\"{x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f}\"\n",
    "                    dimensions = \"0.0 0.0 0.0\"  # Placeholder for height, width, length\n",
    "                    location = \"0.0 0.0 0.0\"    # Placeholder for 3D coordinates\n",
    "                    rotation_y = \"-10.0\"        # Placeholder for rotation\n",
    "\n",
    "                    class_name = yolo_classes[cls_id]\n",
    "                    score_value = score if isinstance(score, float) else float(score)\n",
    "\n",
    "                    f.write(f\"{image_name.split('.')[0]} {track_id} {class_name} {truncated} {occluded} {alpha} {x1:.2f} {y1:.2f} {x2:.2f} {y2:.2f} {dimensions} {location} {rotation_y} {score_value:.3f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
